{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuanGuo/HT-PINN-batch/blob/main/HT_PINN_batch_training_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93DG5Y_upzAr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable, grad\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import ast\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnsywHTMpzA5"
      },
      "outputs": [],
      "source": [
        "class PhysicsInformedNN(nn.Module):\n",
        "\n",
        "  def __init__(self, layer_dim_u, layer_dim_K, input_K=None, inv_params=None, num_pumps=25):\n",
        "    super(PhysicsInformedNN, self).__init__()\n",
        "\n",
        "\n",
        "    self.weights = []\n",
        "\n",
        "    self.preds = None\n",
        "\n",
        "    self.loss = 0.0\n",
        "\n",
        "    self.loss_list = []   \n",
        "    self.loss_dict = {'neum':[0.0], 'diri':[0.0],'u':[0.0],'f':[0.0],'K':[0.0],'pump':[0.0]}\n",
        "    self.loss_container = []\n",
        "\n",
        "    def block(in_feat, out_feat, normalize=False):\n",
        "      layers = [nn.Linear(in_feat, out_feat)]\n",
        "      if normalize:\n",
        "          layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "      # layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "      layers.append(nn.Tanh())\n",
        "      return layers\n",
        "\n",
        "    self.forward_models = []\n",
        "    for i in range(num_pumps):\n",
        "      self.modules = []\n",
        "      for j in range(len(layer_dim_u)-2):\n",
        "        input_dim, output_dim = layer_dim_u[j], layer_dim_u[j+1],\n",
        "        self.modules += block(input_dim, output_dim, normalize=False)\n",
        "      self.modules.append(nn.Linear(output_dim, layer_dim_u[j+2]))\n",
        "      self.forward_models.append(nn.Sequential(*self.modules))\n",
        "\n",
        "\n",
        "    self.modules = []\n",
        "    for j in range(len(layer_dim_K)-2):\n",
        "      input_dim, output_dim = layer_dim_K[j], layer_dim_K[j+1],\n",
        "      self.modules += block(input_dim, output_dim, normalize=False)\n",
        "    self.modules.append(nn.Linear(output_dim, layer_dim_K[j+2]))\n",
        "    self.inverse_model = nn.Sequential(*self.modules)\n",
        "\n",
        "\n",
        "    for i in range(num_pumps): \n",
        "      loss_dict = {'neum':[], 'diri':[],'u':[],'f':[],'K':[],'pump':[]}\n",
        "      self.loss_container.append(loss_dict)\n",
        "\n",
        "\n",
        "  def net_u(self, x, y, pid): # head u, including Dirichlet BCs\n",
        "    H = torch.cat((x,y),1)\n",
        "    u = self.forward_models[pid](H)\n",
        "    return u\n",
        "  \n",
        "  def net_K(self, x, y): # hydraulic conductivity K\n",
        "\n",
        "    H = torch.cat((x,y),1)\n",
        "    K = self.inverse_model(H)\n",
        "\n",
        "    return K\n",
        "  \n",
        "\n",
        "  def net_du(self, x, y, pid): # first-order derivative match, inlcuding Neumann BCs\n",
        "\n",
        "    u = self.net_u(x, y, pid)\n",
        "\n",
        "    u_x = grad(u.sum(), x, create_graph=True, retain_graph=True)[0]\n",
        "    u_y = grad(u.sum(), y, create_graph=True)[0]\n",
        "\n",
        "    return u_x.requires_grad_(True), u_y.requires_grad_(True)\n",
        "\n",
        "  def net_dK(self, x, y): # first-order derivative of K\n",
        "    K = self.net_K(x, y)#, self.weights_u, self.biases_u)\n",
        "\n",
        "    K_x = grad(K.sum(), x, create_graph=True)[0]\n",
        "    K_y = grad(K.sum(), y, create_graph=True)[0]\n",
        "\n",
        "    return K_x.requires_grad_(True), K_y.requires_grad_(True)\n",
        "\n",
        "\n",
        "  def net_f(self, x, y, pid): # general PDE match, usually formulated in higher-order\n",
        "\n",
        "    u_x, u_y = self.net_du(x, y, pid)\n",
        "    u_yy = grad(u_y.sum(), y, create_graph=True)[0]\n",
        "    u_xx = grad(u_x.sum(), x, create_graph=True)[0]\n",
        "\n",
        "    K = self.net_K(x, y)\n",
        "    K_x, K_y = self.net_dK(x, y)\n",
        "\n",
        "    f = K*(u_yy + u_xx) + K_x*u_x + K_y*u_y\n",
        "\n",
        "    return f.requires_grad_(True)\n",
        "\n",
        "  def forward(self, x_tensors, y_tensors, pid, keys=None):\n",
        "\n",
        "    if keys is None:\n",
        "      keys = x_tensors.keys()\n",
        "    else:\n",
        "      preds = dict()\n",
        "      for i in keys:\n",
        "          preds[i] = None\n",
        "\n",
        "    for i in keys:\n",
        "\n",
        "      if i == 'neum':\n",
        "        dudx_pred, dudy_pred = self.net_du(x_tensors[i], y_tensors[i], pid)\n",
        "        preds[i] = dudy_pred\n",
        "\n",
        "      elif i == 'f':\n",
        "        f_pred = self.net_f(x_tensors[i], y_tensors[i], pid)\n",
        "        preds[i] = f_pred\n",
        "\n",
        "      elif i == 'u':\n",
        "        u_pred = self.net_u(x_tensors[i], y_tensors[i], pid) \n",
        "        preds[i] = u_pred\n",
        "          \n",
        "      elif i == 'K':\n",
        "        K_pred = self.net_K(x_tensors[i], y_tensors[i])\n",
        "\n",
        "        preds[i] = K_pred\n",
        "          \n",
        "      elif i == 'diri':\n",
        "        diri_pred = self.net_u(x_tensors[i], y_tensors[i], pid) \n",
        "        preds[i] = diri_pred\n",
        "\n",
        "      elif i == 'pump':\n",
        "        p_pred = self.net_f(x_tensors[i], y_tensors[i], pid)\n",
        "        preds[i] = p_pred\n",
        "\n",
        "    return preds\n",
        "\n",
        "  def loss_func(self, pred_dict, true_dict, pump_id, weights=None):\n",
        "  \n",
        "    loss = torch.tensor(0.0, dtype=torch.float32)\n",
        "    keys = pred_dict.keys()\n",
        "\n",
        "    if weights is None:\n",
        "      weights = dict()\n",
        "      for i in keys:\n",
        "        weights[i] = 1.0\n",
        "\n",
        "    for i in keys:\n",
        "      res = pred_dict[i] - true_dict[i]\n",
        "      loss += weights[i]*torch.mean(res.pow(2))\n",
        "      r = torch.mean(res.pow(2)).item()\n",
        "      self.loss_container[pump_id][i].append(r*weights[i])\n",
        "    return loss.requires_grad_()\n",
        "\n",
        "\n",
        "  def unzip_train_dict(self, train_dict, keys=None):\n",
        "    if keys is None:\n",
        "      keys = train_dict.keys()\n",
        "\n",
        "    x_tensors = dict()\n",
        "    y_tensors = dict()\n",
        "    true_dict = dict()\n",
        "\n",
        "    for i in keys:\n",
        "      x_tensors[i] = train_dict[i][0]\n",
        "      y_tensors[i] = train_dict[i][1]\n",
        "      true_dict[i] = train_dict[i][2]\n",
        "\n",
        "    return (x_tensors, y_tensors, true_dict)\n",
        "\n",
        "  def train(self, iter, data_batch, loss_func, optimizer, pred_keys=None, loss_weights=None, pump_id_list=[0], print_interval=1000):\n",
        "      \n",
        "    if pred_keys is None:\n",
        "      pred_keys= data_batch[0].keys()\n",
        "    for i in range(iter):\n",
        "      optimizer.zero_grad()\n",
        "      loss = 0.0\n",
        "      for pump_id in pump_id_list:\n",
        "        train_dict = data_batch[pump_id]\n",
        "\n",
        "        (x_tensors, y_tensors, true_dict) = self.unzip_train_dict(train_dict,pred_keys)\n",
        "        pred_dict = self.forward(x_tensors, y_tensors, pump_id, keys=pred_keys)\n",
        "        loss += loss_func(pred_dict, true_dict, pump_id, loss_weights)\n",
        "\n",
        "      loss.backward()\n",
        "      self.callback(loss.detach().numpy().squeeze())\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "  def callback(self, loss):\n",
        "    self.loss_list.append(loss)\n",
        "\n",
        "  def coor_shift(self, X, lbs, ubs):\n",
        "    return 2.0*(X - lbs) / (ubs - lbs) - 1\n",
        "\n",
        "  def data_loader(self, X, u, lbs, ubs):\n",
        "              \n",
        "    X = self.coor_shift(X, lbs, ubs)\n",
        "\n",
        "    x_tensor = torch.tensor(X[:,0:1], requires_grad=True, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(X[:,1:2], requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "    u_tensor = torch.tensor(u, dtype=torch.float32)\n",
        "    \n",
        "    return (x_tensor, y_tensor, u_tensor)\n",
        "\n",
        "  def predict(self, X_input, pid=0, target='u'):\n",
        "    x_tensor = torch.tensor(X_input[:,0:1], dtype=torch.float32, requires_grad=True)\n",
        "    y_tensor = torch.tensor(X_input[:,1:2], dtype=torch.float32, requires_grad=True)\n",
        "    pred = None\n",
        "    if target == 'u':\n",
        "      pred = self.net_u(x_tensor, y_tensor, pid).detach().numpy().squeeze()\n",
        "    elif target == 'du':\n",
        "      dudx, dudy = self.net_du(x_tensor, y_tensor, pid)\n",
        "      return dudx.detach().numpy().squeeze(), dudy.detach().numpy().squeeze()\n",
        "    elif target == 'f':\n",
        "      pred = self.net_f(x_tensor, y_tensor, pid).detach().numpy().squeeze()\n",
        "\n",
        "    elif target == 'K':\n",
        "      pred = self.net_K(x_tensor, y_tensor).detach().numpy().squeeze()\n",
        "\n",
        "    return pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6ALaWubt9aZ"
      },
      "outputs": [],
      "source": [
        "################ hydraulic conductivty field ###################\n",
        "logK = np.loadtxt('./data/logK_field.txt')\n",
        "K = np.exp(logK)\n",
        "(nx,ny) = logK.shape\n",
        "\n",
        "################ K measurement locations ###################\n",
        "K_measure_id = np.loadtxt('./data/K_measure_id_61.txt').astype(int)\n",
        "\n",
        "################ pumping well locations ###################\n",
        "num_wells = 25\n",
        "well_id = np.arange(num_wells)\n",
        "pump_cell_idx = np.loadtxt('./data/pump_well_id_25.txt').astype(int)\n",
        "\n",
        "################ hydraulic heads under each pumping event ###################\n",
        "heads = np.empty((nx*ny, num_wells))\n",
        "for i in range(num_wells):\n",
        "  head = np.loadtxt('./data/heads/head_pump'+str(i)+'.txt') \n",
        "  heads[:,i]=head.T.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPEPmUM0pmaw"
      },
      "outputs": [],
      "source": [
        "############### define domain with (0,0) at center ######\n",
        "Lox, Loy = 1, 1\n",
        "dx, dy = Lox/nx, Loy/ny\n",
        "x = np.arange((-Lox/2+dx/2),(Lox/2),dx)\n",
        "y = np.arange((-Lox/2+dx/2),(Lox/2),dy)\n",
        "\n",
        "X, Y = np.meshgrid(x,y)\n",
        "\n",
        "X_star = np.hstack((X.flatten()[:,None], Y.flatten()[:,None]))\n",
        "\n",
        "#################  relax region defination ##################\n",
        "r = 48  # half-length of relax region\n",
        "\n",
        "pump_row_idx = np.repeat(pump_cell_idx[:,None],2*r-1,1)\n",
        "pump_row_idx = pump_row_idx - np.arange(-r+1,r)\n",
        "around_idx = [pump_row_idx]\n",
        "for i in range(1,r):\n",
        "  around_idx = [pump_row_idx-nx*i] + around_idx + [nx*i+pump_row_idx]\n",
        "around_idx = np.hstack(around_idx)\n",
        "around_idx = np.delete(around_idx,int(((2*r-1)**2-1)/2),1)\n",
        "\n",
        "#################  boundary cell locations ##################\n",
        "id1 = np.where(X.flatten() == min(x))\n",
        "id2 = np.where(X.flatten() == max(x))\n",
        "\n",
        "id3 = np.where(Y.flatten() == min(y))\n",
        "id4 = np.where(Y.flatten() == max(y))\n",
        "xbound_idx = np.unique(np.hstack((id1,id2)))\n",
        "ybound_idx = np.unique(np.hstack((id3,id4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLJF7c_auq_R"
      },
      "outputs": [],
      "source": [
        "#################### set font size ####################\n",
        "axis_label_font_size = 30\n",
        "axis_tick_font_size = 30\n",
        "legend_fontszie = 25\n",
        "colorbar_font_size = 25\n",
        "title_size = 30\n",
        "\n",
        "################ show logK field ###################\n",
        "fig2,ax2 = plt.subplots(figsize=(7,6))\n",
        "\n",
        "im2 = ax2.pcolor(X,Y,logK, cmap='jet')\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')\n",
        "fig2.colorbar(im2, ax=ax2, orientation='vertical')\n",
        "ax2.scatter(X_star[K_measure_id,0], X_star[K_measure_id,1], marker='v', zorder=1, alpha= 1, c='m', s=30)\n",
        "ax2.set_title(\"lnK field\",fontsize=title_size)\n",
        "\n",
        "################ show water heads under a pumping event (pe) ###################\n",
        "pe = 12\n",
        "head = heads[:,pe].reshape((nx,ny))\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8,7))\n",
        "im = ax.pcolor(X,Y,head)\n",
        "\n",
        "ax.scatter(X_star[pump_cell_idx[pe],0], X_star[pump_cell_idx[pe],1], marker=\"o\", zorder=1, alpha= 1, c='r', s=40, label=\"pump\")\n",
        "ax.scatter(X_star[around_idx[pe],0], X_star[around_idx[pe],1], zorder=1, alpha= 1.0, c='orange', s=10, label=\"relax\")\n",
        "ax.scatter(X_star[ybound_idx,0], X_star[ybound_idx,1], marker='s', zorder=1, alpha= 1, c='k', s=20, label=\"neum\")\n",
        "ax.scatter(X_star[xbound_idx,0], X_star[xbound_idx,1], marker='s', zorder=1, alpha= 1, c='dodgerblue', s=20, label=\"diri\")\n",
        "ax.scatter(X_star[np.delete(pump_cell_idx,pe),0], X_star[np.delete(pump_cell_idx,pe),1], zorder=1, alpha= 1, c='purple', s=20, label=\"u\")\n",
        "\n",
        "ax.set_xlabel('x',fontsize=axis_label_font_size)\n",
        "ax.set_ylabel('y',fontsize=axis_label_font_size)\n",
        "labels = [-0.4, -0.2, 0, 0.2, 0.4]\n",
        "ax.set_xticks(labels)\n",
        "ax.set_xticks(labels)\n",
        "ax.set_xticklabels(labels,Fontsize=axis_tick_font_size,ha='center')\n",
        "ax.set_yticklabels(labels,Fontsize=axis_tick_font_size,rotation=90, ha='right', va='center')\n",
        "\n",
        "ax.legend(loc='upper left',ncol=1,prop={'size': legend_fontszie}, framealpha=0, facecolor='none',borderpad=0.01,labelspacing=0.001,handletextpad=0.5, handlelength=0.2,columnspacing=0.02)\n",
        "\n",
        "cbar = fig.colorbar(im, ax=ax,ticks=[-0.125, -0.010])\n",
        "cbar.ax.set_ylabel('[cm]',labelpad=-30,rotation=0,va='top',size=25)\n",
        "cbar.ax.set_yticklabels(['-12.5', '-1.0']) \n",
        "cbar.ax.tick_params(labelsize=colorbar_font_size) \n",
        "ax.set_title('Water head of p'+str(pe),fontsize=title_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1SWYAsUuwjh"
      },
      "outputs": [],
      "source": [
        "############# create PINN instance #############\n",
        "\n",
        "hnu = 50 # number of hidden unit in each layer of net u\n",
        "hnK = 50 # number of hidden unit in each layer of net K\n",
        "\n",
        "layers = [2, hnu, hnu, hnu, hnu, hnu, hnu, 1]\n",
        "layers_K = [2, hnK, hnK, hnK, hnK, hnK, hnK, 1]\n",
        "\n",
        "model =PhysicsInformedNN(layers,layers_K)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsi63E2WuzM4"
      },
      "outputs": [],
      "source": [
        "############# fixed data used for all nets ##########\n",
        "\n",
        "############# K measurements ##########\n",
        "K_star = K.flatten()[:,None]\n",
        "K_train = K_star[K_measure_id]\n",
        "X_K_train = X_star[K_measure_id]\n",
        "\n",
        "# Domain bounds   \n",
        "lbs = np.array([min(x),min(y)])\n",
        "ubs = np.array([max(x),max(y)])\n",
        "    \n",
        "################### Dirichlet BCs (left & right bound)  ##########\n",
        "N_diri = 64 # No. of point for Dirichlet BCs\n",
        "# left (x=0) and right (x=1)\n",
        "xx = X_star[xbound_idx]\n",
        "uu = np.zeros((xx.shape[0],1))\n",
        "\n",
        "X_diri_train = xx\n",
        "diri_train = uu\n",
        "\n",
        "################### Neumann BCs (top & bottom bound)  #############\n",
        "N_neum = 64  # No. of points for Neumann BCs\n",
        "# bottom (y = 0) and top (y=1)\n",
        "yy = X_star[ybound_idx]\n",
        "du = np.zeros((yy.shape[0],1))\n",
        "\n",
        "X_neum_train = yy\n",
        "neum_train = du\n",
        "\n",
        "# transform data for network training\n",
        "neum_data = model.data_loader(X_neum_train, neum_train, lbs, ubs)\n",
        "diri_data = model.data_loader(X_diri_train, diri_train, lbs, ubs)\n",
        "K_data = model.data_loader(X_K_train, K_train, lbs, ubs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nljdeRbu4te"
      },
      "outputs": [],
      "source": [
        "############# specific data in each individual pumping events ##########\n",
        "\n",
        "Qp = 30             # approximated water amount changing rate in pumping grid\n",
        "\n",
        "n_batches = 10      # number of batches\n",
        "Nf = 900            # number of collocated grids in each batch\n",
        "data_batch = []     # one batch of training data\n",
        "data_batches = []   # container of batches\n",
        "\n",
        "for db in range(n_batches):\n",
        "  data_batch = []\n",
        "  for jj in range(num_wells):\n",
        "\n",
        "    # pump well and pump rate \n",
        "    X_pump_train = X_star[pump_cell_idx[jj]][None,:]\n",
        "    pump_train = np.array([[Qp]])\n",
        "\n",
        "    # water heads at monitor wells\n",
        "    u_star = heads[:,jj][:,None]\n",
        "    X_u_train = X_star[np.delete(pump_cell_idx,jj)]\n",
        "    u_train = u_star[np.delete(pump_cell_idx,jj)]\n",
        "\n",
        "    # add noise to data and normalize\n",
        "    u_train = u_train + np.random.normal(0,np.abs(0.05*u_train),u_train.shape)\n",
        "    u_train_norm = np.linalg.norm(u_train)\n",
        "    u_train = u_train/u_train_norm\n",
        "\n",
        "    # cells outside pump (relax) region set for PDE constraints\n",
        "    region_idx = np.hstack((pump_cell_idx[jj],around_idx[jj],xbound_idx,ybound_idx))\n",
        "    X_f_space = np.delete(X_star, region_idx, 0)\n",
        "\n",
        "    collocate_id = np.random.randint(0, X_f_space.shape[0], Nf)\n",
        "\n",
        "    # collocate_id_mat[db,jj,:] = collocate_id\n",
        "    X_f_train = X_f_space[collocate_id]\n",
        "    f_train = np.zeros((X_f_train.shape[0],1))\n",
        "\n",
        "    # transform data for network training\n",
        "    f_data = model.data_loader(X_f_train, f_train, lbs, ubs)\n",
        "    u_data = model.data_loader(X_u_train, u_train, lbs, ubs)\n",
        "    pump_data = model.data_loader(X_pump_train, pump_train, lbs, ubs)\n",
        "\n",
        "    # Assemble data batch containing training data\n",
        "    # training data is in dict format: key: name -> value: (x,y,val)\n",
        "    train_dict = {\n",
        "      'neum': neum_data,\n",
        "      'diri': diri_data,\n",
        "      'u': u_data,\n",
        "      'f': f_data,\n",
        "      'K': K_data,\n",
        "      'pump': pump_data\n",
        "    }\n",
        "\n",
        "    data_batch.append(train_dict)\n",
        "  data_batches.append(data_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIrSSXvOy8Vd"
      },
      "outputs": [],
      "source": [
        "# select pumping events for forward models\n",
        "pump_id_list = [0, 4, 12, 20, 24]\n",
        "\n",
        "npump = len(pump_id_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZflB6IIpzBP"
      },
      "outputs": [],
      "source": [
        "# hyper-parameters setup\n",
        "\n",
        "# loss type aggregated in total loss\n",
        "pred_ks = ['diri', 'neum', 'u', 'pump','f','K']\n",
        "\n",
        "loss_weights = {\n",
        "  'f': 50.0,\n",
        "  'u': 10000.0,\n",
        "  'neum': 10000.0,\n",
        "  'pump': 1.0,\n",
        "  'K': 1000.0,\n",
        "  'diri': 20000.0\n",
        "}\n",
        "\n",
        "# networks weights to tune\n",
        "for pid in pump_id_list:\n",
        "  model.weights += model.forward_models[pid].parameters()\n",
        "model.weights += model.inverse_model.parameters()\n",
        "\n",
        "# print out loss by interval = p_intervals\n",
        "p_intervals = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-32kWyxE2Hq"
      },
      "outputs": [],
      "source": [
        "# save hyper-parameters\n",
        "hyper_param = copy.copy(loss_weights)\n",
        "hyper_param['epoch'] = [0]\n",
        "hyper_param['lr'] = []\n",
        "hyper_param['Qp'] = Qp\n",
        "hyper_param['r'] = r\n",
        "hyper_param['hnK'] = hnK\n",
        "hyper_param['hnu'] = hnu\n",
        "hyper_param['lenK'] = len(layers_K)\n",
        "hyper_param['lenu'] = len(layers)\n",
        "hyper_param['act_K'] = 'tanh'\n",
        "hyper_param['act_u'] = 'tanh'\n",
        "hyper_param['out_K'] = 'linear'\n",
        "hyper_param['out_u'] = 'linear'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YHVoCUJNujX"
      },
      "outputs": [],
      "source": [
        "# training process\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam(params=model.weights, lr=1e-3)\n",
        "\n",
        "num_epoch = 500\n",
        "iter = 1\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  for batch_id in range(n_batches):\n",
        "    data_batch = data_batches[batch_id]\n",
        "    model.train(iter, data_batch, model.loss_func, optimizer, pred_ks, loss_weights, pump_id_list, p_intervals)\n",
        "\n",
        "  if epoch%p_intervals==0 or epoch==num_epoch-1:\n",
        "    elapsed = time.time() - start_time\n",
        "    print('Epoch#: %d, Iter#: %d, Loss: %.4f, Time: %.4f' % (epoch, len(model.loss_list), model.loss_list[-1], elapsed))\n",
        "    print_loss = dict()\n",
        "    for pid in pump_id_list:\n",
        "      print_loss = \"Pump \"+ str(pid) + \": \"\n",
        "      for k in pred_ks:\n",
        "        s = k+\":\"+str(model.loss_container[pid][k][-1])+\"; \"\n",
        "        print_loss += s\n",
        "      print(print_loss)\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print('Training time: %.4f' % (elapsed))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjKyxNGx4aNk"
      },
      "outputs": [],
      "source": [
        "# tune learn rate down\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam(params=model.weights, lr=1e-4)\n",
        "\n",
        "num_epoch = 1500\n",
        "iter = 1\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  for batch_id in range(n_batches):\n",
        "    data_batch = data_batches[batch_id]\n",
        "    model.train(iter, data_batch, model.loss_func, optimizer, pred_ks, loss_weights, pump_id_list, p_intervals)\n",
        "\n",
        "  if epoch%p_intervals==0 or epoch==num_epoch-1:\n",
        "    elapsed = time.time() - start_time\n",
        "    print('Epoch#: %d, Iter#: %d, Loss: %.4f, Time: %.4f' % (epoch, len(model.loss_list), model.loss_list[-1], elapsed))\n",
        "    print_loss = dict()\n",
        "    for pid in pump_id_list:\n",
        "      print_loss = \"Pump \"+ str(pid) + \": \"\n",
        "      for k in pred_ks:\n",
        "        s = k+\":\"+str(model.loss_container[pid][k][-1])+\"; \"\n",
        "        print_loss += s\n",
        "      print(print_loss)\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print('Training time: %.4f' % (elapsed))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dClWzqVlV6dn"
      },
      "outputs": [],
      "source": [
        "X_pred= model.coor_shift(X_star, lbs, ubs)\n",
        "error_u_list = []\n",
        "for ti in pump_id_list:\n",
        "\n",
        "  u_true = heads[:,ti]\n",
        "  u_pred = model.predict(X_pred, pid=ti, target='u')\n",
        "  u_train = u_true[np.delete(pump_cell_idx,ti)]\n",
        "  u_train_norm = np.linalg.norm(u_train)\n",
        "  u_pred = u_pred*u_train_norm\n",
        "\n",
        "  u_err = u_pred-u_true\n",
        "  error_u = np.linalg.norm(u_err,2)/np.linalg.norm(u_true,2)\n",
        "  error_u_list.append(error_u)\n",
        "\n",
        "print(error_u_list)\n",
        "print(\"Min Err: \", min(error_u_list))\n",
        "print(\"Max Err: \", max(error_u_list))\n",
        "print(\"mean Err: \", np.mean(error_u_list))\n",
        "print(\"std Err: \", np.std(error_u_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKiTO1kOpzBR"
      },
      "outputs": [],
      "source": [
        "#set font size\n",
        "axis_label_font_size = 28\n",
        "axis_tick_font_size = 30\n",
        "legend_fontszie = 25\n",
        "colorbar_font_size = 30\n",
        "title_size = 30\n",
        "\n",
        "ti = pump_id_list[-2]\n",
        "X_pred= model.coor_shift(X_star, lbs, ubs)\n",
        "u_true = heads[:,ti]\n",
        "\n",
        "u_pred = model.predict(X_pred, pid=ti, target='u')\n",
        "u_train = u_true[np.delete(pump_cell_idx,ti)]\n",
        "u_train_norm = np.linalg.norm(u_train)\n",
        "u_pred = u_pred*u_train_norm\n",
        "\n",
        "u_err = u_pred-u_true\n",
        "error_u = np.linalg.norm(u_err,2)/np.linalg.norm(u_true,2)\n",
        "print('Relative Residual of forward problem: %.4f' % (error_u))\n",
        "\n",
        "u_pred = u_pred.reshape((nx,ny))\n",
        "u_true = u_true.reshape((nx,ny))\n",
        "\n",
        "################### hydraulic head plot: colormap and contour ##################\n",
        "\n",
        "scaler_min = np.min(u_pred)*0.95\n",
        "scaler_max = np.max(u_pred)*0.95\n",
        "scaler_len = scaler_max - scaler_min\n",
        "\n",
        "#set font size\n",
        "axis_label_font_size = 28\n",
        "axis_tick_font_size = 30\n",
        "legend_fontszie = 25\n",
        "colorbar_font_size = 30\n",
        "title_size = 30\n",
        "\n",
        "fig_forward_2, axs = plt.subplots(1,2,figsize=(12,5.6),frameon=False, sharex=False,sharey=False)\n",
        "\n",
        "scaler_min = np.min(u_pred)*0.95\n",
        "scaler_max = np.max(u_pred)*0.95\n",
        "scaler_len = scaler_max - scaler_min\n",
        "\n",
        "lvls = np.linspace(scaler_min,scaler_max,7)\n",
        "\n",
        "ax = axs[0]\n",
        "im = ax.pcolormesh(X, Y, u_true, vmin=scaler_min, vmax=scaler_max)\n",
        "\n",
        "CT = ax.contour(X, Y, u_true, levels=lvls,cmap=\"coolwarm\")\n",
        "ax.clabel(CT,fontsize=15,inline=True,inline_spacing=1,fmt='%.1f')\n",
        "\n",
        "ax.set_xlabel('x',fontsize=axis_label_font_size)\n",
        "ax.set_ylabel('y',fontsize=axis_label_font_size)\n",
        "\n",
        "ticks = [-0.4, 0.0, 0.4]\n",
        "\n",
        "labels = [0.1, 0.5, 0.9]\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(labels,Fontsize=axis_tick_font_size,ha='center')\n",
        "ax.set_yticklabels(labels,Fontsize=axis_tick_font_size,rotation=90, ha='right', va='center')\n",
        "ax.set_title('(A). True Water Heads',fontsize=title_size)\n",
        "\n",
        "ax = axs[1]\n",
        "im = ax.pcolormesh(X, Y, u_pred, vmin=scaler_min, vmax=scaler_max)\n",
        "CP = ax.contour(X, Y, u_pred,levels=lvls,cmap=\"coolwarm\")\n",
        "ax.clabel(CP,fontsize=15,inline=True,fmt='%.1f')\n",
        "ax.set_xlabel('x',fontsize=axis_label_font_size)\n",
        "\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(labels,Fontsize=axis_tick_font_size,ha='center')\n",
        "ax.set_yticklabels(labels,Fontsize=axis_tick_font_size,rotation=90, ha='right', va='center')\n",
        "ax.set_title('(B). Prediction from $NN^{%d}$' % (ti+1), fontsize=title_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiqyVLCxpzBS"
      },
      "outputs": [],
      "source": [
        "################### hydraulic conductivity colormap plot: 2D ##################\n",
        "K_pred = model.predict(X_pred, pid=ti, target='K')\n",
        "# K_pred = K_pred*K_train_norm\n",
        "K_true = K.flatten()\n",
        "\n",
        "K_err = K_true - K_pred\n",
        "error_K = np.linalg.norm(K_err,2)/np.linalg.norm(K_true,2)\n",
        "print(\"Relative Residual: %.4f\" % error_K)\n",
        "K_pred = K_pred.reshape((nx,ny))\n",
        "\n",
        "minlK, maxlK = np.min(logK), np.max(logK)\n",
        "\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(7,6))\n",
        "im = ax.pcolormesh(X,Y,logK,cmap='jet')\n",
        "im.set_clim(minlK, maxlK )\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(labels,Fontsize=axis_tick_font_size,ha='center')\n",
        "ax.set_yticklabels(labels,Fontsize=axis_tick_font_size,rotation=90, ha='right', va='center')\n",
        "ax.set_title('(A). Reference $lnT$ field',fontsize=title_size)\n",
        "\n",
        "logK_pred = np.nan_to_num(np.log(K_pred),nan=minlK)\n",
        "fig,ax = plt.subplots(figsize=(7,6))\n",
        "im = ax.pcolormesh(X,Y, logK_pred,cmap='jet')\n",
        "im.set_clim(minlK, maxlK)\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(labels,Fontsize=axis_tick_font_size,ha='center')\n",
        "ax.set_yticklabels(labels,Fontsize=axis_tick_font_size,rotation=90, ha='right', va='center')\n",
        "ax.set_title('(B). Estimation from $TNN$',fontsize=title_size)\n",
        "\n",
        "\n",
        "# threshold 10%\n",
        "thres = 0.1\n",
        "K_len = maxlK-minlK\n",
        "\n",
        "# acc = np.divide(abs(logK-K_pred),abs(K))\n",
        "acc = abs(logK-logK_pred)/K_len\n",
        "\n",
        "\n",
        "print(\"Accuracy with 10%% threshold: %.4f\" % (sum(sum(acc<thres))/(nx*ny)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmVysxZoWCvl"
      },
      "outputs": [],
      "source": [
        "model_dir = \"./model_coeff/\"\n",
        "\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.makedirs(model_dir)\n",
        "\n",
        "torch.save(model.inverse_model, model_dir+\"/inverse.pth\")\n",
        "\n",
        "for fid in pump_id_list: \n",
        "  forward_net = model.forward_models[fid]\n",
        "  torch.save(forward_net, model_dir+\"/forward_\"+str(fid)+\".pth\")\n",
        "\n",
        "############## save hyper-parameters for reproduce ##################\n",
        "with open( model_dir+\"/hyper_param.txt\",\"w\") as f:\n",
        "  f.write(str(hyper_param))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_GGy_-CWcj8"
      },
      "outputs": [],
      "source": [
        "model = PhysicsInformedNN(layers,layers_K)\n",
        "\n",
        "load_dir = \"./model_coeff/\"\n",
        "\n",
        "model.inverse_model = torch.load(load_dir+\"/inverse.pth\")\n",
        "for fid in pump_id_list:\n",
        "  model.forward_models[fid] = torch.load(load_dir+\"/forward_\"+str(fid)+\".pth\")\n",
        "\n",
        "with open(load_dir+\"/hyper_param.txt\",\"r\") as file:\n",
        "  line = file.read()\n",
        "  loaded_hyper_param = ast.literal_eval(line)\n",
        "print(loaded_hyper_param)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "Copy of HT_PINN_batch_training.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
